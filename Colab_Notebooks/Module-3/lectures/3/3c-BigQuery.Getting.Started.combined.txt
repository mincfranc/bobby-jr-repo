# Documentation and resources
**Big Query**

- Colab has an example notebook on BigQuery too.  File > Open notebook > Examples > Getting Started with BigQuery.

- Also a Big Query Snippets Example Notebook

- [BigQuery Documentation]( https://cloud.google.com/bigquery/docs )

- [Open Data Sets]( https://console.cloud.google.com/marketplace/browse?filter=solution-type:dataset )

- [Reddit - list of data sets available on BQ]( https://www.reddit.com/r/bigquery/wiki/datasets )





**Big Query Console**  

- [Google Cloud Console]( https://console.cloud.google.com )

- Make sure your project is selected

- Scroll down to BigQuery on the left menu

- [Setup and query instructions]( https://cloud.google.com/bigquery/docs/quickstarts/query-public-dataset-console )



**SQL**

- [Kaggle Intro to SQL]( https://www.kaggle.com/learn/intro-to-sql ) uses BigQuery

- [Kaggle Advanced SQL]( https://www.kaggle.com/learn/advanced-sql )
#  Linking BigQuery to Colab
## Getting started
**You will only need to do this part once.**



1. Use the [Cloud Resource Manager](https://console.cloud.google.com/cloud-resource-manager) to Create a Cloud Platform project if you do not already have one.



    - Create Project

    - Project Name

    - Location



2. [Enable BigQuery APIs](https://console.cloud.google.com/flows/enableapi?apiid=bigquery) for the project



**Note:** You get 1 TB/month of free queries for open datasets

- Kaggle gives you 5 TB/month free



## Imports
### Provide your credentials
## Optional: Enable data table display



Colab includes the ``google.colab.data_table`` package that can be used to display large pandas dataframes as an interactive data table.

It can be enabled with:
If you would prefer to return to the classic Pandas dataframe display, you can disable this by running:

```python

%unload_ext google.colab.data_table

```
## List projects



In order to query BigQuery, you will need to specify a project ID.  To get a list of project IDs associated with your account, run the following command.
## Declare the Cloud project ID which will be used throughout this notebook
## Samples data set



The [GSOD table](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=samples&t=gsod&page=table) in the Samples data set contains weather information collected by NOAA, such as precipitation amounts and wind speeds from late 1929 to early 2010.

# Use BigQuery via magics



The `google.cloud.bigquery` library also includes a magic command which runs a query and either displays the result or saves it to a variable as a `DataFrame`.
# Use BigQuery through google-cloud-bigquery



See [BigQuery documentation](https://cloud.google.com/bigquery/docs) and [library reference documentation](https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/usage.html).

## Sample approximately 2000 random rows
### Count total number of rows
### Describe the sampled data
### View the first 10 rows
# Use BigQuery through pandas-gbq



The `pandas-gbq` library is a community led project by the pandas community. It covers basic functionality, such as writing a DataFrame to BigQuery and running a query, but as a third-party library it may not handle all BigQuery features or use cases.



[Pandas GBQ Documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_gbq.html)
# Syntax highlighting

`google.colab.syntax` can be used to add syntax highlighting to any Python string literals which are used in a query later.
from google.cloud import bigquery

from google.colab import auth

from google.colab import syntax

import pandas as pd

auth.authenticate_user()

print('Authenticated')
%load_ext google.colab.data_table

# %unload_ext google.colab.data_table
!gcloud projects list --sort-by=projectId
project_id = "cool-monolith-286222"

# Display query output immediately



%%bigquery --project {project_id}

SELECT

  COUNT(1) as total_rows

FROM `bigquery-public-data.samples.gsod`
# Save output in a variable `df`



%%bigquery df --project {project_id}

SELECT

  COUNT(1) as total_rows

FROM `bigquery-public-data.samples.gsod`
f'{df.iloc[0,0]:_}'
client = bigquery.Client(project=project_id)



row_count = client.query('''

  SELECT

    COUNT(1) as total

  FROM `bigquery-public-data.samples.gsod`

  '''

).to_dataframe()["total"][0]



print(f'Full dataset has {row_count:_} rows')

sample_count = 2000

df = client.query(f'''

  SELECT

    *

  FROM

    `bigquery-public-data.samples.gsod`

  WHERE RAND() < {sample_count}/{row_count}

''').to_dataframe()

df.describe().transpose().astype({"count": int})
df.head(10)
df.isnull().sum()
# 10 highest total_precipitation samples

(

df

  .sort_values('total_precipitation', ascending=False)

  .head(10)

  [['station_number', 'year', 'month', 'day', 'total_precipitation']]

)

df = pd.io.gbq.read_gbq('''

  SELECT

    name, SUM(number) as count

  FROM

    bigquery-public-data.usa_names.usa_1910_2013

  WHERE

    state = 'TX'

  GROUP BY

    name

  ORDER BY

    count DESC

  LIMIT

    100

  ''', project_id=project_id, dialect='standard'

)



df.head()
query = syntax.sql('''

  SELECT

    COUNT(1) as total_rows

  FROM

    `bigquery-public-data.samples.gsod`

''')



pd.io.gbq.read_gbq(query, project_id=project_id, dialect='standard')
type(query)
